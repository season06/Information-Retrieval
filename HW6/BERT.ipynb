{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import timedelta\n",
    "from copy import deepcopy\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ml_metrics import mapk\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForMultipleChoice\n",
    "\n",
    "# Random seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# CUDA device\n",
    "use_cuda_device = 0\n",
    "torch.cuda.set_device(use_cuda_device)\n",
    "print(\"Using CUDA device: %d\" % torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "document_csv_path = './data/documents.csv'\n",
    "training_csv_path = './data/train_queries.csv'\n",
    "testing_csv_path = './data/test_queries.csv'\n",
    "\n",
    "# Input limitation\n",
    "max_query_length = 64\n",
    "max_input_length = 512\n",
    "num_negatives = 3    # num. of negative documents to pair with a positive document\n",
    "\n",
    "# Model finetuning\n",
    "model_name_or_path = \"bert-base-uncased\"\n",
    "max_epochs = 1\n",
    "learning_rate = 3e-5\n",
    "dev_set_ratio = 0.2   # make a ratio of training set as development set for rescoring weight sniffing\n",
    "max_patience = 0      # earlystop if avg. loss on development set doesn't decrease for num. of epochs\n",
    "batch_size = 2        # num. of inputs = 8 requires ~9200 MB VRAM (num. of inputs = batch_size * (num_negatives + 1))\n",
    "num_workers = 2       # num. of jobs for pytorch dataloader\n",
    "\n",
    "# Save paths\n",
    "save_model_path = \"models/bert_base_uncased\"  # assign `None` for not saving the model\n",
    "save_submission_path = \"bm25_bert_rescoring.csv\"\n",
    "K = 1000   # for MAP@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea172d2720d48dcacb2aac056b164d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050563437a3b43f89cb886efbaadc920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress: 100000/100000\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>LA123190-0105</td>\n",
       "      <td>CLERKS AT 13 STORES ARRESTED AFTER MINORS BUY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>LA123190-0108</td>\n",
       "      <td>LOOKING TO 1991; \\n  THE NEW YEAR PROMISES TRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>LA123190-0117</td>\n",
       "      <td>LOCAL; \\n  GIRL, 14, DIES IN DRIVE-BY INCIDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>LA123190-0119</td>\n",
       "      <td>GREECE, ISRAEL HIT BY EXODUS FROM ALBANIA \\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>LA123190-0124</td>\n",
       "      <td>&lt;Empty Document&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_id                                           doc_text\n",
       "99995  LA123190-0105  CLERKS AT 13 STORES ARRESTED AFTER MINORS BUY ...\n",
       "99996  LA123190-0108  LOOKING TO 1991; \\n  THE NEW YEAR PROMISES TRE...\n",
       "99997  LA123190-0117  LOCAL; \\n  GIRL, 14, DIES IN DRIVE-BY INCIDENT...\n",
       "99998  LA123190-0119  GREECE, ISRAEL HIT BY EXODUS FROM ALBANIA \\n  ...\n",
       "99999  LA123190-0124                                   <Empty Document>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and save BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name_or_path)\n",
    "if save_model_path is not None:\n",
    "    save_tokenizer_path = \"%s/tokenizer\" % (save_model_path)\n",
    "    tokenizer.save_pretrained(save_tokenizer_path)\n",
    "\n",
    "# Collect mapping of all document id and text\n",
    "doc_id_to_text = {}\n",
    "doc_df = pd.read_csv(document_csv_path)\n",
    "doc_df.fillna(\"<Empty Document>\", inplace=True)\n",
    "id_text_pair = zip(doc_df[\"doc_id\"], doc_df[\"doc_text\"])\n",
    "for i, pair in enumerate(id_text_pair, start=1):\n",
    "    doc_id, doc_text = pair\n",
    "    doc_id_to_text[doc_id] = doc_text\n",
    "    \n",
    "    print(\"Progress: %d/%d\\r\" % (i, len(doc_df)), end='')\n",
    "    \n",
    "doc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape: (96, 5)\n",
      "dev_df shape: (24, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>pos_doc_ids</th>\n",
       "      <th>bm25_top1000</th>\n",
       "      <th>bm25_top1000_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>641</td>\n",
       "      <td>Valdez wildlife marine life</td>\n",
       "      <td>FT911-1460 FT931-15213 FT931-16010 FT933-7162 ...</td>\n",
       "      <td>LA120989-0014 LA032390-0003 LA040889-0009 LA03...</td>\n",
       "      <td>34.16304495 32.97577181 31.31040724 30.8527172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>642</td>\n",
       "      <td>Tiananmen Square protesters</td>\n",
       "      <td>FBIS3-1941 FBIS3-2223 FBIS3-2224 FBIS3-26281 F...</td>\n",
       "      <td>FT922-10319 FT931-8730 FT942-5501 FBIS4-24379 ...</td>\n",
       "      <td>32.38429409 30.71831856 29.63771818 29.4676000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>648</td>\n",
       "      <td>family leave law</td>\n",
       "      <td>FBIS3-43072 FBIS3-61562 FBIS4-25261 FR940323-0...</td>\n",
       "      <td>FR941202-0-00181 FR941202-0-00176 FR941202-0-0...</td>\n",
       "      <td>24.51293307 23.98772391 23.42756181 23.0616218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>649</td>\n",
       "      <td>computer viruses</td>\n",
       "      <td>FBIS3-40468 FBIS3-42979 FBIS3-43017 FBIS4-5044...</td>\n",
       "      <td>FT944-9024 FBIS4-50440 FT921-5724 FT941-13624 ...</td>\n",
       "      <td>27.84369436 27.24267123 26.98326939 26.9108106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>650</td>\n",
       "      <td>tax evasion indicted</td>\n",
       "      <td>LA011689-0065 LA012589-0008 LA012889-0016 LA02...</td>\n",
       "      <td>LA040889-0060 LA053189-0041 LA092590-0146 LA06...</td>\n",
       "      <td>29.72207523 27.98961258 27.73561512 27.3372072...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                   query_text  \\\n",
       "91       641  Valdez wildlife marine life   \n",
       "92       642  Tiananmen Square protesters   \n",
       "93       648             family leave law   \n",
       "94       649             computer viruses   \n",
       "95       650         tax evasion indicted   \n",
       "\n",
       "                                          pos_doc_ids  \\\n",
       "91  FT911-1460 FT931-15213 FT931-16010 FT933-7162 ...   \n",
       "92  FBIS3-1941 FBIS3-2223 FBIS3-2224 FBIS3-26281 F...   \n",
       "93  FBIS3-43072 FBIS3-61562 FBIS4-25261 FR940323-0...   \n",
       "94  FBIS3-40468 FBIS3-42979 FBIS3-43017 FBIS4-5044...   \n",
       "95  LA011689-0065 LA012589-0008 LA012889-0016 LA02...   \n",
       "\n",
       "                                         bm25_top1000  \\\n",
       "91  LA120989-0014 LA032390-0003 LA040889-0009 LA03...   \n",
       "92  FT922-10319 FT931-8730 FT942-5501 FBIS4-24379 ...   \n",
       "93  FR941202-0-00181 FR941202-0-00176 FR941202-0-0...   \n",
       "94  FT944-9024 FBIS4-50440 FT921-5724 FT941-13624 ...   \n",
       "95  LA040889-0060 LA053189-0041 LA092590-0146 LA06...   \n",
       "\n",
       "                                  bm25_top1000_scores  \n",
       "91  34.16304495 32.97577181 31.31040724 30.8527172...  \n",
       "92  32.38429409 30.71831856 29.63771818 29.4676000...  \n",
       "93  24.51293307 23.98772391 23.42756181 23.0616218...  \n",
       "94  27.84369436 27.24267123 26.98326939 26.9108106...  \n",
       "95  29.72207523 27.98961258 27.73561512 27.3372072...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(training_csv_path)\n",
    "dev_df, train_df = np.split(train_df, [int(dev_set_ratio*len(train_df))])\n",
    "dev_df.reset_index(drop=True, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"train_df shape:\", train_df.shape)\n",
    "print(\"dev_df shape:\", dev_df.shape)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8849 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 96/96\n",
      "Progress: 24/24\n",
      "num. train_instances: 7679\n",
      "num. dev_instances: 1677\n",
      "input_ids.T shape: torch.Size([4, 512])\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  3199,  3036,  ...,  1012,  1019,  2213],\n",
       "        [  101,  3199,  3036,  ...,  2000,  3477,  2051],\n",
       "        [  101,  3199,  3036,  ...,     0,     0,     0],\n",
       "        [  101,  3199,  3036,  ..., 24534,  9556,  1012]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "doc_id_to_token_ids = {}\n",
    "def preprocess_df(df):\n",
    "    ''' Preprocess DataFrame into training instances for BERT. '''\n",
    "    instances = []\n",
    "    \n",
    "    # Parse CSV\n",
    "    for i, row in df.iterrows():\n",
    "        query_id, query_text, pos_doc_ids, bm25_top1000, _ = row\n",
    "        pos_doc_id_list = pos_doc_ids.split()\n",
    "        pos_doc_id_set = set(pos_doc_id_list)\n",
    "        bm25_top1000_list = bm25_top1000.split()\n",
    "        bm25_top1000_set = set(bm25_top1000_list)\n",
    "\n",
    "        # Pair BM25 neg. with pos. samples\n",
    "        labeled_pos_neg_list = []\n",
    "        for pos_doc_id in pos_doc_id_list:\n",
    "            neg_doc_id_set = bm25_top1000_set - pos_doc_id_set\n",
    "            neg_doc_ids = random.sample(neg_doc_id_set, num_negatives)\n",
    "            pos_position = random.randint(0, num_negatives)\n",
    "            pos_neg_doc_ids = neg_doc_ids\n",
    "            pos_neg_doc_ids.insert(pos_position, pos_doc_id)\n",
    "            labeled_sample = (pos_neg_doc_ids, pos_position)\n",
    "            labeled_pos_neg_list.append(labeled_sample)\n",
    "            \n",
    "        # Make query tokens for BERT\n",
    "        query_tokens = tokenizer.tokenize(query_text)\n",
    "        if len(query_tokens) > max_query_length:  # truncation\n",
    "            query_tokens = query_tokens[:max_query_length]\n",
    "        query_token_ids = tokenizer.convert_tokens_to_ids(query_tokens)\n",
    "        query_token_ids.insert(0, tokenizer.cls_token_id)\n",
    "        query_token_ids.append(tokenizer.sep_token_id)\n",
    "\n",
    "        # Make input instances for all query/doc pairs\n",
    "        for doc_ids, label in labeled_pos_neg_list:\n",
    "            paired_input_ids = []\n",
    "            paired_attention_mask = []\n",
    "            paired_token_type_ids = []\n",
    "            \n",
    "            # Merge all pos/neg inputs as a single sample\n",
    "            for doc_id in doc_ids:\n",
    "                if doc_id in doc_id_to_token_ids:\n",
    "                    doc_token_ids = doc_id_to_token_ids[doc_id]\n",
    "                else:\n",
    "                    doc_text = doc_id_to_text[doc_id]\n",
    "                    doc_tokens = tokenizer.tokenize(doc_text)\n",
    "                    doc_token_ids = tokenizer.convert_tokens_to_ids(doc_tokens)\n",
    "                    doc_id_to_token_ids[doc_id] = doc_token_ids\n",
    "                doc_token_ids.append(tokenizer.sep_token_id)\n",
    "\n",
    "                # make input sequences for BERT\n",
    "                input_ids = query_token_ids + doc_token_ids\n",
    "                token_type_ids = [0 for token_id in query_token_ids]\n",
    "                token_type_ids.extend(1 for token_id in doc_token_ids)\n",
    "                if len(input_ids) > max_input_length:  # truncation\n",
    "                    input_ids = input_ids[:max_input_length]\n",
    "                    token_type_ids = token_type_ids[:max_input_length]\n",
    "                attention_mask = [1 for token_id in input_ids]\n",
    "                \n",
    "                # convert and collect inputs as tensors\n",
    "                input_ids = torch.LongTensor(input_ids)\n",
    "                attention_mask = torch.FloatTensor(attention_mask)\n",
    "                token_type_ids = torch.LongTensor(token_type_ids)\n",
    "                paired_input_ids.append(input_ids)\n",
    "                paired_attention_mask.append(attention_mask)\n",
    "                paired_token_type_ids.append(token_type_ids)\n",
    "            label = torch.LongTensor([label]).squeeze()\n",
    "            \n",
    "            # Pre-pad tensor pairs for efficiency\n",
    "            paired_input_ids = pad_sequence(paired_input_ids, batch_first=True)\n",
    "            paired_attention_mask = pad_sequence(paired_attention_mask, batch_first=True)\n",
    "            paired_token_type_ids = pad_sequence(paired_token_type_ids, batch_first=True)\n",
    "\n",
    "            # collect all inputs as a dictionary\n",
    "            instance = {}\n",
    "            instance['input_ids'] = paired_input_ids.T  # transpose for code efficiency\n",
    "            instance['attention_mask'] = paired_attention_mask.T\n",
    "            instance['token_type_ids'] = paired_token_type_ids.T\n",
    "            instance['label'] = label\n",
    "            instances.append(instance)\n",
    "\n",
    "        print(\"Progress: %d/%d\\r\" % (i+1, len(df)), end='')\n",
    "    print()\n",
    "    return instances\n",
    "\n",
    "train_instances = preprocess_df(train_df)\n",
    "dev_instances = preprocess_df(dev_df)\n",
    "\n",
    "print(\"num. train_instances: %d\" % len(train_instances))\n",
    "print(\"num. dev_instances: %d\" % len(dev_instances))\n",
    "print(\"input_ids.T shape:\", train_instances[0]['input_ids'].T.shape)\n",
    "train_instances[0]['input_ids'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, instances):\n",
    "        self.instances = instances\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        instance = self.instances[i]\n",
    "        input_ids = instance['input_ids']\n",
    "        attention_mask = instance['attention_mask']\n",
    "        token_type_ids = instance['token_type_ids']\n",
    "        label = instance['label']\n",
    "        return input_ids, attention_mask, token_type_ids, label\n",
    "    \n",
    "def get_train_dataloader(instances, batch_size=2, num_workers=4):\n",
    "    def collate_fn(batch):\n",
    "        input_ids, attention_mask, token_type_ids, labels = zip(*batch)\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True).transpose(1,2).contiguous()  # re-transpose\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True).transpose(1,2).contiguous()\n",
    "        token_type_ids = pad_sequence(token_type_ids, batch_first=True).transpose(1,2).contiguous()\n",
    "        labels = torch.stack(labels)\n",
    "        return input_ids, attention_mask, token_type_ids, labels\n",
    "    \n",
    "    dataset = TrainingDataset(instances)\n",
    "    dataloader = DataLoader(dataset, collate_fn=collate_fn, shuffle=True, \\\n",
    "                            batch_size=batch_size, num_workers=num_workers)\n",
    "    return dataloader\n",
    "\n",
    "# Demo\n",
    "dataloader = get_train_dataloader(train_instances)\n",
    "for batch in dataloader:\n",
    "    input_ids, attention_mask, token_type_ids, labels = batch\n",
    "    break\n",
    "    \n",
    "print(input_ids.shape)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMultipleChoice.from_pretrained(model_name_or_path)\n",
    "model.cuda()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, instances):\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    dataloader = get_train_dataloader(instances, batch_size=batch_size, num_workers=num_workers)\n",
    "    for batch in dataloader:\n",
    "        batch = (tensor.cuda() for tensor in batch)\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        \n",
    "        ''' TO-DO: \n",
    "        1. Compute the cross-entropy loss (using built-in loss of BertForMultipleChoice)\n",
    "          (Hint: You need to call a function of model which takes all the 4 tensors in the batch as inputs)\n",
    "          \n",
    "        2. Sum up the loss of all dev-set samples\n",
    "          (Hint: The built-in loss is averaged, so you should multiply it with the batch size)\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids = input_ids,\n",
    "                           token_type_ids = token_type_ids,\n",
    "                           attention_mask = attention_mask,\n",
    "                           labels = labels)\n",
    "            loss = outputs[0]         ### 1. insert_missing_code\n",
    "        total_loss += loss ### 2. insert_missing_code\n",
    "        \n",
    "    avg_loss = total_loss / len(instances)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience, best_dev_loss = 0, 1e10\n",
    "best_state_dict = model.state_dict()\n",
    "\n",
    "start_time = time()\n",
    "dataloader = get_train_dataloader(train_instances, batch_size=batch_size, num_workers=num_workers)\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(dataloader, start=1):\n",
    "        batch = (tensor.cuda() for tensor in batch)\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        \n",
    "        # Backpropogation\n",
    "        ''' TO-DO: \n",
    "        1. Compute the cross-entropy loss (using built-in loss of BertForMultipleChoice)\n",
    "          (Hint: You need to call a function of model which takes all the 4 tensors in the batch as inputs)\n",
    "         \n",
    "        2. Perform backpropogation on the loss (i.e. compute gradients)\n",
    "        3. Optimize the model.\n",
    "          (Hint: These two lines of codes can be found in PyTorch tutorial)\n",
    "        '''\n",
    "        outputs = model(input_ids = input_ids,\n",
    "                           token_type_ids = token_type_ids,\n",
    "                           attention_mask = attention_mask,\n",
    "                           labels = labels)\n",
    "        loss = outputs[0]    ### 1. insert_missing_code\n",
    "        loss.backward()      ### 2. insert_missing_code\n",
    "        optimizer.step()     ### 3. insert_missing_code\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Progress bar with timer ;-)\n",
    "        elapsed_time = time() - start_time\n",
    "        elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "        print(\"Epoch: %d/%d | Batch: %d/%d | loss=%.5f | %s      \\r\" \\\n",
    "              % (epoch, max_epochs, i, len(dataloader), loss, elapsed_time), end='')\n",
    "        \n",
    "    # Save parameters of each epoch\n",
    "    if save_model_path is not None:\n",
    "        save_checkpoint_path = \"%s/epoch_%d\" % (save_model_path, epoch)\n",
    "        model.save_pretrained(save_checkpoint_path)\n",
    "        \n",
    "    # Get avg. loss on development set\n",
    "    print(\"Epoch: %d/%d | Validating...                           \\r\" % (epoch, max_epochs), end='')\n",
    "    dev_loss = validate(model, dev_instances)\n",
    "    elapsed_time = time() - start_time\n",
    "    elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "    print(\"Epoch: %d/%d | dev_loss=%.5f | %s                      \" \\\n",
    "          % (epoch, max_epochs, dev_loss, elapsed_time))\n",
    "    \n",
    "    # Track best checkpoint and earlystop patience\n",
    "    if dev_loss < best_dev_loss:\n",
    "        patience = 0\n",
    "        best_dev_loss = dev_loss\n",
    "        best_state_dict = deepcopy(model.state_dict())\n",
    "        if save_model_path is not None:\n",
    "            model.save_pretrained(save_model_path)\n",
    "    else:\n",
    "        patience += 1\n",
    "    \n",
    "    if patience > max_patience:\n",
    "        print('Earlystop at epoch %d' % epoch)\n",
    "        break\n",
    "        \n",
    "# Restore parameters with best loss on development set\n",
    "model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingDataset(Dataset):\n",
    "    def __init__(self, instances):\n",
    "        self.instances = instances\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        instance = self.instances[i]\n",
    "        input_ids = instance['input_ids']\n",
    "        attention_mask = instance['attention_mask']\n",
    "        token_type_ids = instance['token_type_ids']\n",
    "        input_ids = torch.LongTensor(input_ids)\n",
    "        attention_mask = torch.FloatTensor(attention_mask)\n",
    "        token_type_ids = torch.LongTensor(token_type_ids)\n",
    "        return input_ids, attention_mask, token_type_ids, \n",
    "    \n",
    "def get_test_dataloader(instances, batch_size=8, num_workers=4):\n",
    "    def collate_fn(batch):\n",
    "        input_ids, attention_mask, token_type_ids = zip(*batch)\n",
    "        input_ids = pad_sequence(input_ids, batch_first=True).unsqueeze(1)  # predict as single choice\n",
    "        attention_mask = pad_sequence(attention_mask, batch_first=True).unsqueeze(1)\n",
    "        token_type_ids = pad_sequence(token_type_ids, batch_first=True).unsqueeze(1)\n",
    "        return input_ids, attention_mask, token_type_ids\n",
    "    \n",
    "    dataset = TestingDataset(instances)\n",
    "    dataloader = DataLoader(dataset, collate_fn=collate_fn, shuffle=False, \\\n",
    "                            batch_size=batch_size, num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_query_doc_scores(model, df):\n",
    "    model.eval()\n",
    "    start_time = time()\n",
    "\n",
    "    # Parse CSV\n",
    "    query_id_list = df[\"query_id\"]\n",
    "    query_text_list = df[\"query_text\"]\n",
    "    bm25_top1000_list = df[\"bm25_top1000\"]\n",
    "\n",
    "    # Treat {1 query, K documents} as a dataset for prediction\n",
    "    query_doc_scores = []\n",
    "    query_doc_ids = []\n",
    "    rows = zip(query_id_list, query_text_list, bm25_top1000_list)\n",
    "    for qi, row in enumerate(rows, start=1):\n",
    "        query_id, query_text, bm25_top1000 = row\n",
    "        bm25_doc_id_list = bm25_top1000.split()\n",
    "        query_doc_ids.append(bm25_doc_id_list)\n",
    "\n",
    "        #################################################\n",
    "        #    Collect all instances of query/doc pairs\n",
    "        #################################################\n",
    "        query_instances = []\n",
    "\n",
    "        # Make query tokens for BERT\n",
    "        query_tokens = tokenizer.tokenize(query_text)\n",
    "        if len(query_tokens) > max_query_length:  # truncation\n",
    "            query_tokens = query_tokens[:max_query_length]\n",
    "        query_token_ids = tokenizer.convert_tokens_to_ids(query_tokens)\n",
    "        query_token_ids.insert(0, tokenizer.cls_token_id)\n",
    "        query_token_ids.append(tokenizer.sep_token_id)\n",
    "\n",
    "        # Make input instances for all query/doc pairs\n",
    "        for i, doc_id in enumerate(bm25_doc_id_list, start=1):\n",
    "            if doc_id in doc_id_to_token_ids:\n",
    "                doc_token_ids = doc_id_to_token_ids[doc_id]\n",
    "            else:\n",
    "                doc_text = doc_id_to_text[doc_id]\n",
    "                doc_tokens = tokenizer.tokenize(doc_text)\n",
    "                doc_token_ids = tokenizer.convert_tokens_to_ids(doc_tokens)\n",
    "                doc_id_to_token_ids[doc_id] = doc_token_ids\n",
    "            doc_token_ids.append(tokenizer.sep_token_id)\n",
    "\n",
    "            # make input sequences for BERT\n",
    "            input_ids = query_token_ids + doc_token_ids\n",
    "            token_type_ids = [0 for token_id in query_token_ids]\n",
    "            token_type_ids.extend(1 for token_id in doc_token_ids)\n",
    "            if len(input_ids) > max_input_length:  # truncation\n",
    "                input_ids = input_ids[:max_input_length]\n",
    "                token_type_ids = token_type_ids[:max_input_length]\n",
    "            attention_mask = [1 for token_id in input_ids]\n",
    "\n",
    "            # convert and collect inputs as tensors\n",
    "            input_ids = torch.LongTensor(input_ids)\n",
    "            attention_mask = torch.FloatTensor(attention_mask)\n",
    "            token_type_ids = torch.LongTensor(token_type_ids)\n",
    "\n",
    "\n",
    "            # collect all inputs as a dictionary\n",
    "            instance = {}\n",
    "            instance['input_ids'] = input_ids\n",
    "            instance['attention_mask'] = attention_mask\n",
    "            instance['token_type_ids'] = token_type_ids\n",
    "            query_instances.append(instance)\n",
    "\n",
    "        #################################################################\n",
    "        #    Predict relevance scores for all BM25-top-1000 documents\n",
    "        #################################################################\n",
    "        doc_scores = np.empty((0,1))\n",
    "\n",
    "        # Predict scores for each document\n",
    "        dataloader = get_test_dataloader(query_instances, batch_size=batch_size*(num_negatives+1), num_workers=num_workers)\n",
    "        for di, batch in enumerate(dataloader, start=1):\n",
    "            batch = (tensor.cuda() for tensor in batch)\n",
    "            input_ids, attention_mask, token_type_ids = batch\n",
    "            \n",
    "            ''' TO-DO: \n",
    "            1. Compute the logits as relevance scores (using the same function of how you compute built-in loss)\n",
    "              (Hint: You need to call a function of model which takes all the 3 tensors in the batch as inputs)\n",
    "         \n",
    "            2. The scores are still on GPU. Reallocate them on CPU, and convert into numpy arrays.\n",
    "              (Hint: You need to call two functions on the `scores` tensors. You can find them in PyTorch tutorial.)\n",
    "            '''\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids = input_ids,\n",
    "                           token_type_ids = token_type_ids,\n",
    "                           attention_mask = attention_mask)\n",
    "                scores = outputs[0]   ### 1. insert_missing_code_to_compute_logits ###\n",
    "\n",
    "            # merge all scores into a big numpy array\n",
    "            scores = scores.cpu().numpy()  ###insert_missing_function_1()###.###insert_missing_function_2()###  # step 2.\n",
    "            doc_scores = np.vstack((doc_scores, scores))\n",
    "\n",
    "            # Progress bar with timer ;-)\n",
    "            elapsed_time = time() - start_time\n",
    "            elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "            print(\"Query: %d/%d | Progress: %d/%d | %s      \\r\" \\\n",
    "                  % (qi, len(df), di, len(dataloader), elapsed_time), end='')\n",
    "\n",
    "        # merge all query/BM25 document pair scores\n",
    "        query_doc_scores.append(doc_scores)\n",
    "    query_doc_scores = np.hstack(query_doc_scores).T\n",
    "\n",
    "    print()\n",
    "    return query_doc_scores, query_doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_query_doc_scores, dev_query_doc_ids = predict_query_doc_scores(model, dev_df)\n",
    "\n",
    "print('---- Grid search weight for \"BM25 + weight * BERT\" ----')\n",
    "best_map_score, best_bert_weight = -100, 0.0\n",
    "bert_scores = dev_query_doc_scores\n",
    "n_query = dev_query_doc_scores.shape[0]\n",
    "\n",
    "# Get MAP@K of BM25 baseline\n",
    "query_pos_doc_ids = dev_df['pos_doc_ids'].values.tolist()\n",
    "actual = [doc_ids.split() for doc_ids in query_pos_doc_ids]\n",
    "bm25_predicted = [doc_id_list[:K] for doc_id_list in dev_query_doc_ids]\n",
    "map_score = mapk(actual, bm25_predicted, k=K)\n",
    "best_map_score = map_score\n",
    "print(\"weight=%.1f: %.5f  (BM25 baseline)\" % (0, 100*map_score))\n",
    "\n",
    "# Collect BM25 scores into same format of BERT scores\n",
    "''' TO-DO: \n",
    "1. Convert the BM25 top-1000 scores into 2d numpy arrays\n",
    "2. BM25 scores should have the same shape and orders as `dev_query_doc_scores` (i.e. BERT scores)\n",
    "  (Hint: If there are 24 dev-set queries, the shape should be (24, 1000) )\n",
    "'''\n",
    "bm25_scores = np.array([_score.split() for _score in dev_df['bm25_top1000_scores']]).astype(np.float)  ### insert_whatever_you_want_to_meet_the_requirement_in_step2. ###\n",
    "\n",
    "# Grid search for BM25 + BERT rescoring\n",
    "low_bound, high_bound, scale = 0, 5, 1000\n",
    "grids = [i / scale for i in range(low_bound * scale+1, high_bound * scale+1)]\n",
    "for weight in grids:\n",
    "    \n",
    "    ''' TO-DO: \n",
    "    1. Compute the weighted scores using `bm25_scores`, `weight`, and `bert_scores`\n",
    "    '''\n",
    "    weighted_scores = bm25_scores + weight * bert_scores  ### 1. insert_missing_code ###\n",
    "    \n",
    "    # sort index and map to document ids as output\n",
    "    rescore_argsort = np.flip(weighted_scores.argsort(), axis=1)\n",
    "    predicted = []\n",
    "    for i in range(n_query):  # num. of queries\n",
    "        predicted.append([dev_query_doc_ids[i][idx] for idx in rescore_argsort[i]][:K])\n",
    "    map_score = mapk(actual, predicted, k=K)\n",
    "    \n",
    "    # show part of results for human evaluation\n",
    "    if weight * 10 % 2 == 0:\n",
    "        print(\"weight=%.1f: %.5f\" % (weight, 100*map_score))\n",
    "        \n",
    "    # track weight with best MAP@10\n",
    "    if map_score > best_map_score:\n",
    "        best_map_score = map_score\n",
    "        best_bert_weight = weight\n",
    "print(\"\\nHighest MAP@%d = %.5f found at weight=%.3f\" % (K, 100*best_map_score, best_bert_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict BERT scores for testing set\n",
    "test_df = pd.read_csv(testing_csv_path)\n",
    "query_id_list = test_df[\"query_id\"]\n",
    "n_query = len(query_id_list)\n",
    "test_query_doc_scores, test_query_doc_ids = predict_query_doc_scores(model, test_df)\n",
    "bert_scores = test_query_doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescore query/document score with BM25 + BERT\n",
    "bm25_scores = [scores.split() for scores in test_df[\"bm25_top1000_scores\"]]  # parse into 2d list of string\n",
    "bm25_scores = [[float(score) for score in scores] for scores in bm25_scores]  # convert to float\n",
    "bm25_scores = np.array(bm25_scores)\n",
    "\n",
    "''' TO-DO: \n",
    "1. Compute the weighted scores using `bm25_scores`, `best_bert_weight`, and `bert_scores`\n",
    "'''\n",
    "weighted_scores = bm25_scores + best_bert_weight * bert_scores   ### 1. insesrt_missing_code ###\n",
    "\n",
    "# Rerank document ids with new scores\n",
    "rescore_argsort = np.flip(weighted_scores.argsort(), axis=1)\n",
    "ranked_doc_id_list = []\n",
    "for i in range(n_query):  # num. of queries\n",
    "    ranked_doc_id_list.append([test_query_doc_ids[i][idx] for idx in rescore_argsort[i]][:K])\n",
    "ranked_doc_ids = [' '.join(doc_id_list) for doc_id_list in ranked_doc_id_list]\n",
    "\n",
    "# Save reranked results for submission\n",
    "data = {'query_id': query_id_list, 'ranked_doc_ids': ranked_doc_ids}\n",
    "submission_df = pd.DataFrame(data)\n",
    "submission_df.reset_index(drop=True, inplace=True)\n",
    "submission_df.to_csv(save_submission_path, index=False)\n",
    "print(\"Saved submission file as `%s`\" % save_submission_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
